tax_table(ps)[,4],
tax_table(ps)[,5],
tax_table(ps)[,6],
tax_table(ps)[,7], sep="_") %>%
str_remove("k__") %>% str_remove("p__") %>% str_remove("c__") %>% str_remove("o__") %>% str_remove("f__") %>% str_remove("g__") %>% str_remove("s__") %>%
str_replace(pattern = "_:_",replacement = ": ")
df <- data.frame(TaxaName=pretty_names,Sequence=taxa_names(ps))
saveRDS(df,"./Output/Pl/SequenceNames_and_Taxonomy.RDS")
View(ps.noncontam)
ps.noncontam <- prune_samples(ps.noncontam@sam_data$Location != "Blank", ps.noncontam)
# Save RDS object for Phyloseq
saveRDS(ps.noncontam, file = "./Output/Pl/clean_phyloseq_object.RDS")
View(ps.noncontam)
# Final Filtering
# load processed data
ps = readRDS(file = "./Output/Pl/clean_phyloseq_object.RDS")
# quick peek at ps object
sample_names(ps)
rank_names(ps)
sample_variables(ps)
otu_table(ps)[1:5, 1:5]
tax_table(ps)[1:5, 1:6]
# Change sequences to unique IDs to make viewing easier
seqs_ITS = taxa_names(ps)
names(seqs_ITS) <- 1:length(seqs_ITS) # save seqs and IDs combination
taxa_names(ps) <- names(seqs_ITS)
tax_table(ps)[1:5, 1:6]
## Removing less prevalent sequences
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
TotalAbundance = taxa_sums(ps),
tax_table(ps))
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps, "Phylum"))
#  Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps1 = prune_taxa(keepTaxa, ps)
View(seqtab.nochim)
View(ps.noncontam)
View(seqtab.nochim)
View(meta)
# re-load point
seqtab.nochim <- readRDS("./Output/Pl/dada2_seqtable.RDS")
taxa <- readRDS("./Output/Pl/RDP_Taxonomy_from_dada2.RDS")
# Hand off to Phyloseq ####
otu <- otu_table(seqtab.nochim,taxa_are_rows = FALSE)
tax <- tax_table(taxa)
met <- sample_data(meta)
row.names(met) <- row.names(meta)
ps <- phyloseq(otu,met,tax)
# Find controlsamples (extraction negatives) and clean ####
contams <- decontam::isContaminant(otu_table(ps),neg = ps@sam_data$Location == "Blank",method = "prevalence")
# Remove contaminants
for (i in 1:nrow(meta)){
df.track$beforeDecontam[i] <- sum(ps@otu_table[i,])
}
ps.noncontam <- prune_taxa(!contams$contaminant, ps)
for (i in 1:nrow(meta)){
df.track$afterDecontam[i] <- sum(ps.noncontam@otu_table[i,])
}
# REMOVE NON-FUNGI and empty samples/taxa ####
ps.noncontam <- subset_taxa(ps.noncontam, Kingdom == "k__Fungi")
for (i in 1:nrow(meta)){
df.track$fungiOnly[i] <- sum(ps.noncontam@otu_table[i,])
}
ps.noncontam <- subset_taxa(ps.noncontam, taxa_sums(ps.noncontam) > 0)
ps.noncontam <- subset_samples(ps.noncontam, sample_sums(ps.noncontam) > 0)
for (i in 1:nrow(meta)){
df.track$nonEmpty[i] <- sum(ps.noncontam@otu_table[i,])
}
# Save DNA sequences apart from rownames (from subsetted ps object)
seqs <- taxa_names(ps)
seqs <- DNAStringSet(seqs)
saveRDS(seqs,"./Output/Pl/ASV_reference_sequences.RDS")
pretty_names <- paste("FungalASV",1:length(taxa_names(ps)),":",
tax_table(ps)[,2],
tax_table(ps)[,3],
tax_table(ps)[,4],
tax_table(ps)[,5],
tax_table(ps)[,6],
tax_table(ps)[,7], sep="_") %>%
str_remove("k__") %>% str_remove("p__") %>% str_remove("c__") %>% str_remove("o__") %>% str_remove("f__") %>% str_remove("g__") %>% str_remove("s__") %>%
str_replace(pattern = "_:_",replacement = ": ")
df <- data.frame(TaxaName=pretty_names,Sequence=taxa_names(ps))
saveRDS(df,"./Output/Pl/SequenceNames_and_Taxonomy.RDS")
ps.noncontam <- prune_samples(ps.noncontam@sam_data$Island != "Blank", ps.noncontam)
# Save RDS object for Phyloseq
saveRDS(ps.noncontam, file = "./Output/Pl/clean_phyloseq_object.RDS")
# Final Filtering
# load processed data
ps = readRDS(file = "./Output/Pl/clean_phyloseq_object.RDS")
View(ps)
View(meta)
# quick peek at ps object
sample_names(ps)
rank_names(ps)
sample_variables(ps)
otu_table(ps)[1:5, 1:5]
tax_table(ps)[1:5, 1:6]
# Change sequences to unique IDs to make viewing easier
seqs_ITS = taxa_names(ps)
names(seqs_ITS) <- 1:length(seqs_ITS) # save seqs and IDs combination
taxa_names(ps) <- names(seqs_ITS)
tax_table(ps)[1:5, 1:6]
## Removing less prevalent sequences
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
TotalAbundance = taxa_sums(ps),
tax_table(ps))
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps, "Phylum"))
#  Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps1 = prune_taxa(keepTaxa, ps)
nBlanks <- 7
startPoint <- 1+nBlanks
View(df.track)
nBlanks <- 6
startPoint <- 1+nBlanks
df.track$afterPrevFilter <- numeric(nrow(df.track))
for (j in startPoint:nrow(meta)){
df.track$afterPrevFilter[j] <- sum(ps1@otu_table[(j-nBlanks),])
}
# Remove samples not associated with an island
ps1 = prune_samples(ps1@sam_data$Island != "", ps1)
df.track$afterLocationFilter_Final <- numeric(nrow(df.track))
for (j in startPoint:nrow(meta)){
df.track$afterLocationFilter_Final[j] <- sum(ps1@otu_table[(j-nBlanks),])
}
# Final ps object
saveRDS(ps1, file = "./Output/Pl/final_phyloseq_object.RDS")
write.csv(df.track, file = "./Output/Pl/FinalTrackReads.csv", row.names = TRUE)
library(phyloseq)
library(vegan)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ggpubr)
library(broom)
library(RColorBrewer)
library(RgoogleMaps)
library(metagMisc)
library(shiny)
library(viridis)
library(svglite)
library(gdtools)
library(VennDiagram)
library(indicspecies)
library(geosphere)
library(ecodist)
# Color palette
pal = c("#6b5456","#6abf2a","#70acbe","#01c95b","#c00014","#31332f","#f7d000","#abba00")
col_island <- viridis(7)
names(col_island) <- c("Hantu", "Jong", "Kusu", "Raffles Lighthouse", "Semakau", "Sisters", "Sultan Shoal")
theme_set(theme_bw())
#### Analysis ####
ps1 <- readRDS("./Output/Pl/final_phyloseq_object.RDS")
taxtable.update <- as.data.frame(ps1@tax_table)
for(j in 1:ncol(taxtable.update)){
taxtable.update[,j] <- as.character(taxtable.update[,j])
for(i in 1:nrow(taxtable.update)){
if(!is.na(taxtable.update[i, j])){
textLabel <- strsplit(as.character(taxtable.update[i, j]), split = '_')[[1]][3:length(strsplit(as.character(taxtable.update[i, j]), split = '_')[[1]])]
taxtable.update[i, j] <- paste(textLabel, collapse='_')
}
}
}
# Data Prep for FUNGuild
taxafinal <- taxtable.update
taxafinal$taxonomy <- taxafinal$Species
for(i in 1:nrow(taxafinal)){
taxafinal$taxonomy[i] <- paste(taxafinal[i,-ncol(taxafinal)], collapse = ' ')
}
OTUTable <- as.data.frame(ps1@otu_table)
OTUTable <- as.data.frame(t(OTUTable))
OTUTable$OTU_ID <- row.names(OTUTable)
OTUTable$taxonomy <- taxafinal$taxonomy
OTUTable <- OTUTable[,98:99]
write.csv(OTUTable, "./Output/Pl/FUNGuild_OTU_Table.csv")
# Normalize (relative abundance) ####
ps1ra <- transform_sample_counts(ps1, function(otu){otu/sum(otu)})
### Rarefaction Curves ###
grp <- factor(ps1@sam_data$Island)
cols <- col_island[grp]
rarefaction_curve <- rarecurve(ps1@otu_table, step = 20, col = cols, label = FALSE)
Nmax <- sapply(rarefaction_curve, function(x) max(attr(x, "Subsample")))
Smax <- sapply(rarefaction_curve, max)
svg(filename = "./Output/Pl/Analysis/Rarefaction Curves.svg", )
plot(c(1, max(Nmax)), c(1, max(Smax)), xlab = "Number of Sequences",
ylab = "Number of ASVs", type = "n",
main = "Rarefaction Curves")
for (i in seq_along(rarefaction_curve)) {
N <- attr(rarefaction_curve[[i]], "Subsample")
lines(N, rarefaction_curve[[i]], col = cols[i])
}
legend(9000, 7, legend = names(col_island), col = col_island, lty = 1, cex = 0.8, box.lty = 1)
dev.off()
# Creating a dataframe of the otu table which also includes the Island variables
combineddf <- as.data.frame(ps1@otu_table)
combineddf$Island <- ps1@sam_data$Island
##############
# Creating a phyloseq object where samples are grouped and merged according to Island
island_otu <- combineddf %>%
group_by(Island) %>%
summarise_all(.funs=sum)
rarefaction_curve <- rarecurve(ps1@otu_table, step = 20, col = cols, label = FALSE)
Nmax <- sapply(rarefaction_curve, function(x) max(attr(x, "Subsample")))
Nmax <- sapply(rarefaction_curve, function(x) max(attr(x, "Subsample")))
rarefaction_curve <- rarecurve(ps1@otu_table, step = 20, col = cols, label = FALSE)
Nmax <- sapply(rarefaction_curve, function(x) max(attr(x, "Subsample")))
Smax <- sapply(rarefaction_curve, max)
svg(filename = "./Output/Pl/Analysis/Rarefaction Curves.svg", )
plot(c(1, max(Nmax)), c(1, max(Smax)), xlab = "Number of Sequences",
ylab = "Number of ASVs", type = "n",
main = "Rarefaction Curves")
for (i in seq_along(rarefaction_curve)) {
N <- attr(rarefaction_curve[[i]], "Subsample")
lines(N, rarefaction_curve[[i]], col = cols[i])
}
legend(60000, 20, legend = names(col_island), col = col_island, lty = 1, cex = 0.8, box.lty = 1)
dev.off()
View(met)
View(met)
View(meta)
# Creating a dataframe of the otu table which also includes the Island variables
combineddf <- as.data.frame(ps1@otu_table)
combineddf$Island <- ps1@sam_data$Island
##############
# Creating a phyloseq object where samples are grouped and merged according to Island
island_otu <- combineddf %>%
group_by(Island) %>%
summarise_all(.funs=sum)
names(col_island) <- c("Hantu", "Jong", "Kusu", "Raffles Lighthouse", "Semakau", "Sisters", "Sultan Shoal")
island_otu <- as.data.frame(island_otu)
row.names(island_otu) <- c("Samples_Hantu", "Samples_Jong", "Samples_Kusu", "Samples_Raffles", "Samples_Semakau", "Samples_Sisters", "Samples_Sultan")
island_otu <- island_otu[,-1]
island_meta <- data.frame(Island = c("Hantu", "Jong", "Kusu", "Raffles Lighthouse", "Semakau", "Sisters", "Sultan Shoal"))
row.names(island_meta) <- NULL
row.names(island_meta) <- c("Samples_Hantu", "Samples_Jong", "Samples_Kusu", "Samples_Raffles", "Samples_Semakau", "Samples_Sisters", "Samples_Sultan")
speciesList <- taxtable.update$Species
genusList <- taxtable.update$Genus
genusSpeciesList <- speciesList
for(i in 1:length(speciesList)){
if(!is.na(speciesList[i])){
genusSpeciesList[i] <- paste(genusList[i], speciesList[i], sep = ' ')
}
}
taxtable.update$Genus_species <- genusSpeciesList
island_ps <- phyloseq(otu_table(island_otu, taxa_are_rows=FALSE),
sample_data(island_meta),
tax_table(ps1@tax_table))
# Calculating Relative abundances and plotting bar plots according to Location and Structure
ps_Island_ra <- transform_sample_counts(island_ps, function(otu){otu/sum(otu)})
# Defining function to make bar charts without black lines separating samples. Based on phyloseq function "plot_bar".
simple_plot_bar = function (physeq, x = "Sample", y = "Abundance", fill = NULL, title = NULL,
facet_wrap = NULL) {
mdf = psmelt(physeq)
p = ggplot(mdf, aes_string(x = x, y = y, fill = fill))
p = p + geom_bar(stat = "identity", position = "stack")
p = p + theme_bw() + theme(axis.text=element_text(size=15), axis.title=element_text(size=17,face="bold"),
axis.text.x = element_text(angle = 70, hjust = 1))
p = p + labs(y = "Relative Abundance")
p = p + guides(guide_legend(ncol = 1), fill = guide_legend(ncol = 3))
if (!is.null(facet_wrap)) {
p <- p + facet_wrap(facet_wrap, nrow = 1) + theme(strip.text = element_text(size=15))
}
if (!is.null(title)) {
p <- p + ggtitle(title)
}
return(p)
}
# According to Phylum
ra_Phylum_barplot_island <- simple_plot_bar(ps_Island_ra, x="Island", fill="Phylum") + theme(legend.text=element_text(size=rel(1.5)), legend.title=element_text(size=rel(1.5)), legend.key.size= unit(0.3, "line")) + guides(fill = guide_legend(nrow = 80)) + scale_fill_discrete(labels = sort(unique(taxtable.update$Phylum)))
ggsave(ra_Phylum_barplot_island, filename = "./Output/Pl/Analysis/Relative Abundance of Ohylum by Island - Bar Plot.svg", dpi=300, width = 12, height = 10)
ra_Phylum_barplot_island
simple_plot_bar(ps_Island_ra, x="Island", fill="Kingdom") + theme(legend.text=element_text(size=rel(1.5)), legend.title=element_text(size=rel(1.5)), legend.key.size= unit(0.3, "line")) + guides(fill = guide_legend(nrow = 80)) + scale_fill_discrete(labels = sort(unique(taxtable.update$Phylum)))
ra_Phylum_barplot_all <- simple_plot_bar(ps1ra, x="SampleID", fill="Phylum") + theme(legend.text=element_text(size=rel(1.5)), legend.title=element_text(size=rel(1.5)), legend.key.size= unit(0.3, "line")) + guides(fill = guide_legend(nrow = 80)) + scale_fill_discrete(labels = sort(unique(taxtable.update$Phylum)))
ggsave(ra_Phylum_barplot_all, filename = "./Output/Pl/Analysis/Relative Abundance of Phylum by Sample - Bar Plot.svg", dpi=300, width = 25, height = 10)
ra_Phylum_barplot_all
View(as.data.frame(ps1@tax_table))
# Forward and reverse fastq filenames have the format:
cutFs_raw <- sort(list.files(path, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_raw <- sort(list.files(path, pattern = "_2.fastq.gz", full.names = TRUE))
cut_raw <- sort(list.files(path, pattern = "fastq.gz", full.names = TRUE))
path.filtN <- file.path(path, "N_filtered")
cutFs_filtN <- sort(list.files(path.filtN, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_filtN <- sort(list.files(path.filtN, pattern = "_2.fastq.gz", full.names = TRUE))
cut_filtN <- sort(list.files(path.filtN, pattern = "fastq.gz", full.names = TRUE))
cutFs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_2.fastq.gz", full.names = TRUE))
cut_adaptor <- sort(list.files(path.cut_adaptor, pattern = "fastq.gz", full.names = TRUE))
cutFs_primer <- sort(list.files(path.cut_primer, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_primer <- sort(list.files(path.cut_primer, pattern = "_2.fastq.gz", full.names = TRUE))
cut_primer <- sort(list.files(path.cut_primer, pattern = "fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname) strsplit(basename(fname), "_")[[1]][1]
sample.names <- unname(sapply(cutFs_primer, get.sample.name))
head(sample.names)
## Quality Profiles ##
# Raw
plotQualityProfile(cutFs_raw[6:11])
plotQualityProfile(cutRs_raw[6:11])
# Pre-filtered
plotQualityProfile(cutFs_filtN[6:11])
plotQualityProfile(cutRs_filtN[6:11])
# Adaptor Removed
plotQualityProfile(cutFs_adaptor[6:11])
plotQualityProfile(cutRs_adaptor[6:11])
# Primer Removed
plotQualityProfile(cutFs_primer[6:11])
plotQualityProfile(cutRs_primer[6:11])
## Comparing files and sample properties for each step
library(seqTools)
packageVersion("seqTools")
library(microseq)
packageVersion("microseq")
samples <- sort(list.files(path, pattern = "fastq.gz", full.names = FALSE))
# Comparing number of reads for each sample during each step
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
for (j in 1:length(samples)){
raw_seqs[j] <- nrow(readFastq(cut_raw[j]))
prefiltered_seqs[j] <- nrow(readFastq(cut_filtN[j]))
adaptorremoved_seqs[j] <- nrow(readFastq(cut_adaptor[j]))
primerremoved_seqs[j] <- nrow(readFastq(cut_primer[j]))
}
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
sample_summaries <- data.frame(samples, raw_seqs, prefiltered_seqs, adaptorremoved_seqs, primerremoved_seqs, fractionOfRawDataInFinal_seqs, stringsAsFactors = FALSE)
write.csv(sample_summaries, file = "Number of Sequence Summary.csv")
summary(sample_summaries)
hist(sample_summaries$raw_seqs)
hist(sample_summaries$primerremoved_seqs)
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
# Declaring path to raw data
path <- "../Coral_fastq/Pl"
list.files(path)
# Forward and reverse fastq filenames have the format:
cutFs_raw <- sort(list.files(path, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_raw <- sort(list.files(path, pattern = "_2.fastq.gz", full.names = TRUE))
cut_raw <- sort(list.files(path, pattern = "fastq.gz", full.names = TRUE))
path.filtN <- file.path(path, "N_filtered")
cutFs_filtN <- sort(list.files(path.filtN, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_filtN <- sort(list.files(path.filtN, pattern = "_2.fastq.gz", full.names = TRUE))
cut_filtN <- sort(list.files(path.filtN, pattern = "fastq.gz", full.names = TRUE))
cutFs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_2.fastq.gz", full.names = TRUE))
cut_adaptor <- sort(list.files(path.cut_adaptor, pattern = "fastq.gz", full.names = TRUE))
cutFs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_1.fastq.gz", full.names = TRUE))
# Removing primers
path.cut_primer <- file.path(path, "Primer_Adaptor_Removed")
# Removing adaptors
path.cut_adaptor <- file.path(path, "Adaptor_Removed")
cutFs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_adaptor <- sort(list.files(path.cut_adaptor, pattern = "_2.fastq.gz", full.names = TRUE))
cut_adaptor <- sort(list.files(path.cut_adaptor, pattern = "fastq.gz", full.names = TRUE))
cutFs_primer <- sort(list.files(path.cut_primer, pattern = "_1.fastq.gz", full.names = TRUE))
cutRs_primer <- sort(list.files(path.cut_primer, pattern = "_2.fastq.gz", full.names = TRUE))
cut_primer <- sort(list.files(path.cut_primer, pattern = "fastq.gz", full.names = TRUE))
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname) strsplit(basename(fname), "_")[[1]][1]
sample.names <- unname(sapply(cutFs_primer, get.sample.name))
head(sample.names)
## Comparing files and sample properties for each step
library(seqTools)
packageVersion("seqTools")
library(microseq)
packageVersion("microseq")
samples <- sort(list.files(path, pattern = "fastq.gz", full.names = FALSE))
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
for (j in 1:length(samples)){
raw_seqs[j] <- nrow(readFastq(cut_raw[j]))
prefiltered_seqs[j] <- nrow(readFastq(cut_filtN[j]))
adaptorremoved_seqs[j] <- nrow(readFastq(cut_adaptor[j]))
primerremoved_seqs[j] <- nrow(readFastq(cut_primer[j]))
}
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
sample_summaries <- data.frame(samples, raw_seqs, prefiltered_seqs, adaptorremoved_seqs, primerremoved_seqs, fractionOfRawDataInFinal_seqs, stringsAsFactors = FALSE)
write.csv(sample_summaries, file = "Number of Sequence Summary.csv")
summary(sample_summaries)
hist(sample_summaries$raw_seqs)
hist(sample_summaries$primerremoved_seqs)
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
for (j in 1:length(samples)){
raw_seqs[j] <- nrow(readFastq(cut_raw[j]))
prefiltered_seqs[j] <- nrow(readFastq(cut_filtN[j]))
adaptorremoved_seqs[j] <- nrow(readFastq(cut_adaptor[j]))
primerremoved_seqs[j] <- nrow(readFastq(cut_primer[j]))
}
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
length(cut_raw)
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
for (j in 1:length(samples)){
raw_seqs[j] <- nrow(readFastq(cut_raw[j]))
prefiltered_seqs[j] <- nrow(readFastq(cut_filtN[j]))
adaptorremoved_seqs[j] <- nrow(readFastq(cut_adaptor[j]))
primerremoved_seqs[j] <- nrow(readFastq(cut_primer[j]))
}
raw_seqs
length(samples)
nrow(readFastq(cut_raw[j]))
readFastq(cut_raw[j])
cut_raw[j]
readFastq(cut_raw[j])
raw_seqs[j] <- nrow(microseq::readFastq(cut_raw[j]))
raw_seqs <- numeric(length(cut_raw))
prefiltered_seqs <- numeric(length(cut_raw))
adaptorremoved_seqs <- numeric(length(cut_raw))
primerremoved_seqs <- numeric(length(cut_raw))
for (j in 1:length(samples)){
raw_seqs[j] <- nrow(microseq::readFastq(cut_raw[j]))
prefiltered_seqs[j] <- nrow(microseq::readFastq(cut_filtN[j]))
adaptorremoved_seqs[j] <- nrow(microseq::readFastq(cut_adaptor[j]))
primerremoved_seqs[j] <- nrow(microseq::readFastq(cut_primer[j]))
}
microseq::readFastq(cut_raw[j])
raw_seqs[65] <- nrow(microseq::readFastq(cut_raw[65]))
raw_seqs[j] <- nrow(microseq::readFastq(cut_raw[j]))
microseq::readFastq(cut_raw[65])
nrow(microseq::readFastq(cut_raw[65]))
j
raw_seqs[87] <- nrow(microseq::readFastq(cut_raw[87]))
nrow(microseq::readFastq(cut_raw[87]))
cut_raw[87]
microseq::readFastq(cut_raw[87])
skip_empty <- function(code) {
tryCatch(code,
error = function(c) 0,
)
}
raw_seqs[87] <- skip_empty(nrow(microseq::readFastq(cut_raw[87])))
show_condition <- function(code) {
tryCatch(code,
error = function(c) "error",
warning = function(c) "warning",
message = function(c) "message"
)
}
show_condition(log('a'))
show_condition <- function(code) {
tryCatch(code,
error = function(c) 0,
warning = function(c) "warning",
message = function(c) "message"
)
}
show_condition(log('a'))
show_condition <- function(code) {
tryCatch(code,
error = function(c) 0,
)
}
skip_empty <- function(code) {
tryCatch(code,
error = function(c) 0
)
}
raw_seqs[87] <- skip_empty(nrow(microseq::readFastq(cut_raw[87])))
skip_empty(nrow(microseq::readFastq(cut_raw[87])))
skip_empty(nrow(microseq::readFastq(cut_raw[86])))
nrow(microseq::readFastq(cut_raw[86]))
for (j in 1:length(samples)){
raw_seqs[j] <- skip_empty(nrow(microseq::readFastq(cut_raw[j])))
prefiltered_seqs[j] <- skip_empty(nrow(microseq::readFastq(cut_filtN[j])))
adaptorremoved_seqs[j] <- skip_empty(nrow(microseq::readFastq(cut_adaptor[j])))
primerremoved_seqs[j] <- skip_empty(nrow(microseq::readFastq(cut_primer[j])))
}
fractionOfRawDataInFinal_seqs <- primerremoved_seqs / raw_seqs
sample_summaries <- data.frame(samples, raw_seqs, prefiltered_seqs, adaptorremoved_seqs, primerremoved_seqs, fractionOfRawDataInFinal_seqs, stringsAsFactors = FALSE)
write.csv(sample_summaries, file = "Number of Sequence Summary.csv")
summary(sample_summaries)
hist(sample_summaries$raw_seqs)
hist(sample_summaries$primerremoved_seqs)
hist(sample_summaries$raw_seqs-sample_summaries$primerremoved_seqs)
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps1 = prune_taxa(keepTaxa, ps)
nBlanks <- 6
startPoint <- 1+nBlanks
save.image("D:/Research Data - 2020/Research - Microbiome 2020/Coral Scripts/Environment/Pl/Env1.RData")
